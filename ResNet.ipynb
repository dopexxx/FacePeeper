{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import struct\n",
    "\n",
    "\n",
    "class CELEBRITIES():\n",
    "    def __init__(self, directory):\n",
    "        '''\n",
    "        self.testData = \n",
    "        self.testLabels = \n",
    "        self.trainingData = \n",
    "        self.trainingLabels = \n",
    "        '''\n",
    "        \n",
    "        self.testLabels[self.testLabels == 10] = 0\n",
    "        self.trainingLabels[self.trainingLabels == 10] = 0\n",
    "        \n",
    "        randomIndices = np.random.choice(len(self.trainingLabels), 4000, replace = False)\n",
    "        self.validationData = self.trainingData[randomIndices]\n",
    "        self.validationLabels = self.trainingLabels[randomIndices]\n",
    "        self.trainingData = np.delete(self.trainingData, randomIndices, axis = 0)\n",
    "        self.trainingLabels = np.delete(self.trainingLabels, randomIndices)\n",
    "    \n",
    "    def _load(self, path, labels = False):\n",
    "        with open(path, \"rb\") as fd:\n",
    "            return pickle.load(fd)\n",
    "        \n",
    "    # Shuffle the samples and to pack them into equally sized batches.\n",
    "    def shuffleSamples(self, batchSize = 50):\n",
    "        indices = np.random.permutation(len(self.trainingData))\n",
    "        self.data = self.trainingData[indices]\n",
    "        self.labels = self.trainingLabels[indices]\n",
    "        \n",
    "        self.dataBatches = []\n",
    "        self.labelBatches = []\n",
    "        \n",
    "        for i in range(len(self.data) // batchSize):\n",
    "            ib = i * batchSize\n",
    "            self.dataBatches.append(np.array(self.data[ib:ib+batchSize]))\n",
    "            self.labelBatches.append(np.array(self.labels[ib:ib+batchSize]))\n",
    "    \n",
    "    # Retrieve the training, validation and test data\n",
    "    def getTrainingData(self):\n",
    "        return self.dataBatches, self.labelBatches\n",
    "\n",
    "    def getValidationData(self):\n",
    "        return self.validationData, self.validationLabels\n",
    "    \n",
    "    def getTestData(self):\n",
    "        return self.testData, self.testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "celeb = CELEBRITIES(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPSILON = 1e-3\n",
    "\n",
    "def batch_normalization(x):\n",
    "    mean, var = tf.nn.moments(x, [0, 1, 2])\n",
    "    normBatch = tf.nn.batch_normalization(x, mean, var, None, None, EPSILON)\n",
    "    return normBatch\n",
    "\n",
    "\n",
    "def output_layer(x, targetDim):\n",
    "    weights = tf.get_variable(\"weights\", [x.get_shape()[1], targetDim], \n",
    "                              tf.float32, tf.random_normal_initializer(stddev = 0.02))\n",
    "    biases = tf.get_variable(\"biases\", [targetDim], tf.float32, tf.constant_initializer(0.0))\n",
    "    return tf.matmul(x, weights) + biases\n",
    "\n",
    "\n",
    "def convLayer(x, filter_shape, stride):\n",
    "    '''\n",
    "    Batch normalization, relu and 2D-convolution\n",
    "    :param x: 4D tensor\n",
    "    :param filter_shape: list. [filter_height, filter_width, filter_depth, filter_number]\n",
    "    :param stride: stride size for convolution\n",
    "    :return: 4D tensor.\n",
    "    '''\n",
    "    kernels = tf.get_variable(\"kernels\", filter_shape, tf.float32, tf.random_normal_initializer(stddev = 0.02))\n",
    "    \n",
    "    normBatch = batch_normalization(x)\n",
    "    reluStep = tf.nn.relu(normBatch)\n",
    "    \n",
    "    conv = tf.nn.conv2d(reluStep, kernels, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "    \n",
    "    return conv\n",
    "\n",
    "\n",
    "def residual_block(x, output_channel):\n",
    "    '''\n",
    "    Defines a residual block in ResNet\n",
    "    :param x: 4D tensor\n",
    "    :param output_channel: int. return_tensor.get_shape().as_list()[-1] = output_channel\n",
    "    :return: 4D tensor.\n",
    "    '''\n",
    "    input_channel = x.get_shape().as_list()[-1]\n",
    "\n",
    "    # When it's time to halve the image size, we use stride = 2\n",
    "    if input_channel * 2 == output_channel:\n",
    "        increase_dim = True\n",
    "        stride = 2\n",
    "    elif input_channel == output_channel:\n",
    "        increase_dim = False\n",
    "        stride = 1\n",
    "    else:\n",
    "        raise ValueError('Output and input channels do not match in residual blocks!')\n",
    "\n",
    "    # 1st convolution in block can have stride 1 or 2\n",
    "    with tf.variable_scope('conv1_in_block'):\n",
    "        conv1 = convLayer(x, [3, 3, input_channel, output_channel], stride)\n",
    "    \n",
    "    # 2nd convolution in block has stride 1\n",
    "    with tf.variable_scope('conv2_in_block'):\n",
    "        conv2 = convLayer(conv1, [3, 3, output_channel, output_channel], 1)\n",
    "\n",
    "    # When size of x and conv2 does not match, we add zero pads to increase the\n",
    "    #  depth of x's\n",
    "    if increase_dim is True:\n",
    "        pooled_input = tf.nn.avg_pool(x, ksize=[1, 2, 2, 1],\n",
    "                                      strides=[1, 2, 2, 1], padding='VALID')\n",
    "        padded_input = tf.pad(pooled_input, [[0, 0], [0, 0], [0, 0], [input_channel // 2,\n",
    "                                                                     input_channel // 2]])\n",
    "    else:\n",
    "        padded_input = x\n",
    "\n",
    "    output = conv2 + padded_input\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input images are 112x112x3\n",
    "images = tf.placeholder(tf.float32, [None, 112, 112, 3])\n",
    "desired = tf.placeholder(tf.int64, [None])\n",
    "lr = tf.placeholder(tf.float32, None)\n",
    "\n",
    "\n",
    "# Batch normalize images\n",
    "images = batch_normalization(images)\n",
    "\n",
    "# ResNet. Total layers: 6 + 8 + 12 + 6 + 1 (33 and not 34. Reason: read above)\n",
    "layers = []\n",
    "\n",
    "# 64 kernels (3x3), 6 layers, i=3\n",
    "for i in range(3):\n",
    "    with tf.variable_scope('conv1_%d' %i):\n",
    "        if i==0:\n",
    "            conv1 = residual_block(images, 64)\n",
    "        else:\n",
    "            conv1 = residual_block(layers, 64)\n",
    "        out = tf.nn.relu(conv1)\n",
    "        layers.append(out)\n",
    "\n",
    "# 128 kernels (3x3), 8 layers, i=4\n",
    "for i in range(4):\n",
    "    with tf.variable_scope('conv2_%d' %i):\n",
    "        conv2 = residual_block(layers, 128)\n",
    "        out = tf.nn.relu(conv2)\n",
    "        layers.append(out)\n",
    "    \n",
    "# 256 kernels (3x3), 12 layers, i=6\n",
    "for i in range(6):\n",
    "    with tf.variable_scope('conv3_%d' %i):\n",
    "        conv3 = residual_block(layers, 256)\n",
    "        out = tf.nn.relu(conv3)\n",
    "        layers.append(out)\n",
    "    \n",
    "# 512 kernels (3x3), 6 layers, i=3\n",
    "for i in range(3):\n",
    "    with tf.variable_scope('conv4_%d' %i):\n",
    "        conv4 = residual_block(layers, 512)\n",
    "        out = tf.nn.relu(conv4)\n",
    "        layers.append(out)\n",
    "\n",
    "\n",
    "# Batch normalize layers, relu, global_avg_pool\n",
    "layers = batch_normalization(layers)\n",
    "reluLayer = tf.nn.relu(layers)\n",
    "globalPool = tf.reduce_mean(reluLayer, [1,2])\n",
    "output = output_layer(globalPool, 400)\n",
    "layers.append(output)\n",
    "\n",
    "logits = layers[-1]\n",
    "\n",
    "crossEntropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, desired)\n",
    "crossEntropy = tf.reduce_mean(crossEntropy)\n",
    "\n",
    "trainStep = tf.train.AdamOptimizer(lr).minimize(crossEntropy)\n",
    "\n",
    "accuracy = tf.equal(tf.argmax(tf.nn.softmax(logits), 1), desired)\n",
    "accuracy = tf.reduce_mean(tf.cast(accuracy, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 60*10^4\n",
    "batchSize = 256\n",
    "celeb.shuffleSamples(batchSize)\n",
    "trainingSteps = len(celeb.getTrainingData()[0]) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_fig, acc_ax = plt.subplots(1,1)\n",
    "ce_fig, ce_ax = plt.subplots(1,1)\n",
    "\n",
    "acc = np.zeros(trainingSteps)\n",
    "ce = np.zeros(trainingSteps)\n",
    "vacc = np.zeros(trainingSteps)\n",
    "vce = np.zeros(trainingSteps)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        celeb.shuffleSamples(batchSize)\n",
    "        imageBatches, labelBatches = celeb.getTrainingData()\n",
    "        for batchNumber in range(len(imageBatches)):\n",
    "            trainingImages = imageBatches[batchNumber]\n",
    "            trainingLabels = labelBatches[batchNumber]\n",
    "            \n",
    "            '''\n",
    "            if step < 250:\n",
    "                learningRate = 1e-3\n",
    "            elif step < 350:\n",
    "                learningRate = 8e-4\n",
    "            elif step < 450:\n",
    "                learningRate = 6e-4\n",
    "            elif step < 550:\n",
    "                learningRate = 2e-4\n",
    "            else:\n",
    "                learningRate = 1e-4\n",
    "            \n",
    "            ce[step], acc[step], _ = session.run([crossEntropy, accuracy, trainStep],\n",
    "                                      feed_dict = {images: trainingImages, desired: trainingLabels, lr: learningRate})\n",
    "\n",
    "\n",
    "            if (step % 20 == 0 and step != 0) or step == trainingSteps-1:\n",
    "                saver.save(session, \"./resnet.chkp\", step)\n",
    "\n",
    "                validationImages, validationLabels = celeb.getValidationData()\n",
    "                vce[step-20:step], vacc[step-20:step] = session.run([crossEntropy, accuracy],\n",
    "                                      feed_dict = {images: validationImages, desired: validationLabels, lr: learningRate})\n",
    "                \n",
    "                acc_ax.cla()\n",
    "                acc_ax.plot(acc, color = 'b')\n",
    "                acc_ax.plot(vacc, color = 'r')\n",
    "                acc_fig.canvas.draw()\n",
    "\n",
    "                ce_ax.cla()\n",
    "                ce_ax.plot(ce, color = 'b')\n",
    "                ce_ax.plot(vce, color = 'r')\n",
    "                ce_fig.canvas.draw()\n",
    "            \n",
    "            step += 1\n",
    "            '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, \"./resnet.chkp-\" + str(trainingSteps-1))\n",
    "    \n",
    "    testImages, testLabels = celeb.getTestData()\n",
    "    accuracies = []\n",
    "    for r in range(0, len(testImages), 1000):\n",
    "        ce, acc = session.run([crossEntropy, accuracy], feed_dict = {images: testImages[r:r+1000], desired: testLabels[r:r+1000]})\n",
    "        accuracies.append(acc)\n",
    "    print(np.mean(accuracies))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
